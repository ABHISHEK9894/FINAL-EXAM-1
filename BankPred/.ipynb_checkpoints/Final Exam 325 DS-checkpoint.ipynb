{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3383f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, MinMaxScaler\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29cc93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc46bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dataset\n",
    "\n",
    "bank = pd.read_csv(r'C:\\Users\\Abhishek\\Desktop\\FINAL EXAM\\BankPred\\Bank-Telemarketing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2933234",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c043886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate values in the bank-full dataset are:  12\n",
      "Duplicate values in the bank-full dataset are:  0\n",
      "(36537, 21)\n",
      "(4639, 21)\n"
     ]
    }
   ],
   "source": [
    "# Checking for dupicate values\n",
    "\n",
    "print('Duplicate values in the bank-full dataset are: ', bank.duplicated().sum())\n",
    "\n",
    "# Dropping DUplicate value\n",
    "bank.drop_duplicates(inplace=True)\n",
    "print('Duplicate values in the bank-full dataset are: ', bank.duplicated().sum())\n",
    "\n",
    "bank.replace(['basic.6y','basic.4y', 'basic.9y'], 'basic', inplace=True)\n",
    "\n",
    "# Balancing data\n",
    "bank_major = bank[bank.y=='no'] \n",
    "bank_minor = bank[bank.y=='yes']\n",
    "\n",
    "print(bank_major.shape)\n",
    "print(bank_minor.shape)\n",
    "\n",
    "\n",
    "from sklearn.utils import resample\n",
    "bank_minor = resample(bank_minor,replace = True, n_samples = 36537)\n",
    "\n",
    "bank_df = pd.concat([bank_major, bank_minor])\n",
    "bank_df.shape\n",
    "\n",
    "# Changing to categorical variables\n",
    "bank_df.loan = bank_df.loan.map({'yes':1, 'unknown':0, 'no':0}).astype('int64')\n",
    "bank_df.housing = bank_df.housing.map({'yes':1, 'unknown':0, 'no':0}).astype('int64')\n",
    "bank_df.default = bank_df.default.map({'yes':1, 'unknown':0, 'no':0}).astype('int64')\n",
    "\n",
    "# Label Encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_var =[\"job\", \"marital\", \"education\", \"contact\", \"month\", \"day_of_week\", \"poutcome\",\"y\"]\n",
    "for i in cat_var:\n",
    "    bank_df[i]= le.fit_transform(bank_df[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad05b96a",
   "metadata": {},
   "source": [
    "### Creating Exp and Resp Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3943f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and Y variable\n",
    "\n",
    "Y = bank_df.iloc[:, -1]\n",
    "X = bank_df.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a972a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2115619b",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a97dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into Training and Testing\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, Y ,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2036ee4",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d23b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_dim=20, activation='relu', name= 'input'))\n",
    "model.add(Dense(32, activation='relu', name= 'hidden_1'))\n",
    "model.add(Dense(64,  activation='relu', name= 'hidden_2'))\n",
    "model.add(Dense(128, activation='relu', name= 'hidden_3'))\n",
    "model.add(Dense(256,  activation='relu', name= 'hidden_4'))\n",
    "model.add(Dense(512, activation='relu', name= 'hidden_5'))\n",
    "model.add(Dense(1, input_dim=20, activation='sigmoid', name= 'output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a880786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "400/400 [==============================] - 3s 5ms/step - loss: 0.3728 - accuracy: 0.8394\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.3082 - accuracy: 0.8705\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.2916 - accuracy: 0.8792\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.2808 - accuracy: 0.8855\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 0.2705 - accuracy: 0.8916\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 5s 13ms/step - loss: 0.2618 - accuracy: 0.8965\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 4s 11ms/step - loss: 0.2547 - accuracy: 0.8995\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.2472 - accuracy: 0.9023\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 0.2416 - accuracy: 0.9046\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.2354 - accuracy: 0.9076\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.2271 - accuracy: 0.9115\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 3s 7ms/step - loss: 0.2209 - accuracy: 0.9150\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.2142 - accuracy: 0.9172\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.2091 - accuracy: 0.9207\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 4s 11ms/step - loss: 0.2012 - accuracy: 0.9242\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 5s 13ms/step - loss: 0.1958 - accuracy: 0.9266\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.1895 - accuracy: 0.9295\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.1826 - accuracy: 0.9335\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 3s 7ms/step - loss: 0.1763 - accuracy: 0.9355\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 0.1733 - accuracy: 0.9368\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(learning_rate= 0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics= ['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "fit = model.fit(x_train, y_train, epochs=20, \n",
    "                batch_size=128, shuffle=True, \n",
    "                callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce6b8dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15184), started 0:26:53 ago. (Use '!kill 15184' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-728e459787c46f0a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-728e459787c46f0a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log Model with Tensor Board\n",
    "\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb663ede",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbd0f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686/686 [==============================] - 2s 3ms/step - loss: 0.2122 - accuracy: 0.9244\n"
     ]
    }
   ],
   "source": [
    "pred = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8840e9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 92.44%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], pred[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96cc38",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16e5fce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Abhishek\\Desktop\\Practice Python\\CIS 325\\Final Exam\\Saved Model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(r'C:\\Users\\Abhishek\\Desktop\\FINAL EXAM\\BankPred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6f693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
